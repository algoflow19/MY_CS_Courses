%CS 109 Problem Set Template
%B. E. Burr

\documentclass{article}
	% basic article document class
	% use percent signs to make comments to yourself -- they will not show up.

\usepackage{amsmath}
\usepackage{amssymb}
	% packages that allow mathematical formatting

\usepackage{graphicx}
	% package that allows you to include graphics

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\frenchspacing
	% one space after periods

\usepackage{fancyhdr}
	% allows custom headers

\pagestyle{fancy}

\lhead{CS 109, Stanford University \\ Problem Set 2} 
\rhead{Jace Belere  \\ BackUp}

\cfoot{\thepage}
\renewcommand{\footrulewidth}{0.4pt} 
	%footer

\begin{document}
\thispagestyle{fancy} %shows header/footer

\begin{enumerate}


	\item 

		
		 We Just Tranform the given condition to get the answer.
		
		$P(EF) \geq P(E) + P(F)-1$  (Bonferroni’s Inequality)
		
		$1 \geq P(E) + P(F)-P(EF)$
		
		$1-P(E)\geq P(F)-P(E|F)P(F)$
		
		$P(E^c)\geq P(F)(1-P(E|F))$
		
		$P(E^c)\geq P(F)P(E^c|F)$
		
		$P(E^c)\geq P(E^cF)$
		
		So we know that Bonferroni’s Inequality always hold.
	\item For the following question. We let J be the event that the engineer program in Java and C be the event that the engineer program in C++.
	
	
	\begin{enumerate}
	\item It's easy to know that $P(CJ)=P(C|J)P(J)$, so the answer is 0.098.
	\item We use Bayes' Theorem. $P(J|C)=0.245$
	\end{enumerate}
	\item \begin{enumerate}
	\item Let's evaluate the probability of that a robot doesn't get flagged is $0.3^3=0.027$, so the probability of that a robot get flagged is 0.973. We use the same method get the probability of that a person get flagged is 0.142625.
	\item Let F be the event that the player gets flagged, R be the event that robort are cheating with robots. Beacuse we don't get the $P(F)$ yet, we use the extented form of Bayes' Theorem to get the answer is $0.431$.
	\end{enumerate}
	\item Let W be the event that a computer running operating system
W get infected, and X be the event that a computer running operating system
X get infected. We expect $P(W)*0.7+P(X)*0.3$ of all computers are get infected. Then we easily get the answer is $\frac{P(W)*0.7}{P(W)*0.7+P(X)*0.3}=\frac{7}{13}$.
	\item \begin{enumerate}
	\item Let N be the event that the email is non-spam, and G be the event that the mail is marked GOOD. $q=P(N|G)$, $P(N)=p$. We use the extented form of Bayes' Theorem and get $q=\frac{ P(G|N)P(N) }{P(G|N)P(N)+P(G|N^c)P(N^c)} =\frac{p}{p+0.1(1-p)}$. 
	\item $q=P(N|G)$, p=$P(N)$, thus $P(N)=P(N|G)+P(N|G^c)$, which is $p=q+P(N|G^c)$, so $p\geq q$. Draw a WEIEN Graph.
	\end{enumerate}
	\item \begin{enumerate}
	\item First, we treat the two cards is a two-elements secquence, and we know that all secquence is equally likely to appear. Since $PP(E|F)=\frac{P(EF)}{P(F)}$, and it's not diffcult to f	igure out that P(EF) is $\frac{3+3}{52\times51}$and P(F) is $\frac{51+51}{52\times51}$, we know that $PP(E|F)=\frac{3}{51}$.
	\item We know that $P(E)=P(E|G)+P(E|G^c)$, and $P(E|G^c)=0$, so $P(E)=P(E|G)=\frac{2\times{4 \choose 2}}{52\times51}$.
	\end{enumerate}
	\item \begin{enumerate}
	\item Let O be the event that at least one of the two emails is spam, and B be the event that both emails are spam. We know that $P(B)=P(B|O)+P(B|O^c)$, and $P(B|O^c)=0$, so $P(B)=P(B|O)$, we get $P(B|O)=0.64$.
	\item It's 0.8. The question is likely to ask that if you reveiced two emails and you randomly choose one of the emails found it is a spam, what is the probability of another email is spam. Since whether each email message is spam is an independent event from the other, we know that the answwer is 0.8.
	\end{enumerate}
	\item Those problems are all combintion problems.
	
	\begin{enumerate}
	\item $1-(1-p)^5$.
	\item $(1-p)^3 p^2  {5 \choose 2}$.
	\item $1-(1-p)^5-(1-p)^4 p{5\choose1}$.
	\end{enumerate}
	\item $\lceil \frac{\lg\frac{5}{2}}{\lg\frac{1}{1-p}} \rceil $.
	\newpage
	\item \begin{enumerate}
	\item Let $ro$ be the event that r1 was assined 1, $rt$ be the event that r2 was assigned 1, and N be the event that $ro\neq rt$. We know that the funation return 1 with the probability $P(ro|N)$. We use Bayes' Theorem and get $P(ro|N)=\frac{P(N|ro)P(ro)}{P(N)}=\frac{(1-p)p}{2(1-p)p}=\frac{1}{2}$.
	\item We know that the if $ro$ happened, then we must get 0, and if $ro^c$ happened, we must get 1. So the P(simpleRandom returns 1) is $(1-p)$.
	\end{enumerate}
	\item We can figure out the both of William's parents have one brown-eyed gene and one blue-eyed gene.
	\begin{enumerate}
	\item $\frac{1}{4}$.
	\item There are three forms of the possible eyed-color genes of William. We will figure out each of them and then get the probability that William's first child will have blue eyes. If William has two brown-eyed genes, it's impossible to have a blue-eyes child; If William has two blue-eyed genes, he must have a blue-eyed child; If William has one blue-eyed genes and one brown-eyed genes, he has $\frac{1}{2}$ chance to have a blue-eyed child. We final get the answer is 0.5.
	\item Let A be the event that William have at least one brown-eyed gene; BN be the event that William have one blue-eyed and brown-eyed gene; NN be the event that William have two brown-eyed gene.  We would like to figure out the $P(BN|A)$ and $P(NN|A)$ first to get the final answer. Using Bayes' Therom, we get $P(BN|A)=\frac{2}{3}$ and $P(NN|A)=\frac{1}{3}$, then it's easy to get the answer is $\frac{2}{3}$.
	\end{enumerate}
	\item \begin{enumerate}
	\item From the problem, we know that $P(T_1 T_2 | G)=0.72$. Since $P(T_1 |G)P(T_2 |G)=P(T_1 T_2 | G)$ hold, we know $T_1$ and $T_2$ are conditionally independent given G.
	\item From the problem, we know that $P(T_1 |G^c)=P(T_2 |G^c)=P(T_1 T_2 |G^c)=0$, so $P(T_1 |G)P(T_2 |G)=P(T_1 T_2 | G)$ hold, and thus $T 1$ and $T 2$  are conditionally independent given $G^c$.
	\item $P(T_1)=P(T_1 | G^c)+P(T_1 |G^c)=0.8$.
	\item $P(T_2)=P(T_2 | G^c)+P(T_2 |G^c)=0.9$.
	\item $P(T_1 T_2 )=P(T_1 T_2 | G)+P(T_1 T_2 | G^c)=0.72 $, so $P(T_1 T_2 )=P(T_1 )P(T_2 )$ hold, $T_1$ and $T_2$ is independent.
	\end{enumerate}
	\item Let W be the event that robot observe the window. Using Bayes's Throme, $P(L_2 | W)=\frac{P(W|L_2 ) P(L_2 )}{P(W|L_1 )P(L_1 ) + P(W|L_2 ) P(L_2 )}=\frac{27}{41}$, thus $P(L_1 | W)=1-P(L_2 | W)=\frac{14}{41}$.
\end{enumerate}




\end{document}